{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BpSQRfameJGi",
    "colab_type": "text"
   },
   "source": [
    "# Prep 1: steps to install the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pcBwjJFPeJGj",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 926.0
    },
    "outputId": "4a2ab816-2b6b-4b99-a786-8f75b163e85a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py_entitymatching\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/d3/2eacdb4ee0e268eb4c041fc2921e880262658b24e15ae470559fb1999eab/py_entitymatching-0.3.1.tar.gz (2.0MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0MB 2.8MB/s \n",
      "\u001b[?25hCollecting PyPrind (from py_entitymatching)\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/b3/c3420d9a05e8fd0677907aab873998afd473af41aaf8d3bc557e8f35832c/PyPrind-2.11.2.tar.gz\n",
      "Collecting py_stringsimjoin==0.3.0 (from py_entitymatching)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/32/28a76b430e092a330850707e34f89419ce77b06dc303e6c5f6cd701ad5ba/py_stringsimjoin-0.3.0.tar.gz (786kB)\n",
      "\u001b[K     |████████████████████████████████| 788kB 38.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from py_entitymatching) (0.6.1)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python2.7/dist-packages (from py_entitymatching) (2.4.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python2.7/dist-packages (from py_entitymatching) (0.20.3)\n",
      "Requirement already satisfied: pandas-profiling>=1.4.0 in /usr/local/lib/python2.7/dist-packages (from py_entitymatching) (1.4.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python2.7/dist-packages (from py_stringsimjoin==0.3.0->py_entitymatching) (0.12.5)\n",
      "Requirement already satisfied: pandas>=0.16.0 in /usr/local/lib/python2.7/dist-packages (from py_stringsimjoin==0.3.0->py_entitymatching) (0.24.2)\n",
      "Collecting py_stringmatching>=0.2.1 (from py_stringsimjoin==0.3.0->py_entitymatching)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/a3/89c3d02bbf1e24868673702ebd38a3b76259cb124a5d26d46a050d3fccf2/py_stringmatching-0.4.1.tar.gz (646kB)\n",
      "\u001b[K     |████████████████████████████████| 655kB 33.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from py_stringsimjoin==0.3.0->py_entitymatching) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python2.7/dist-packages (from scikit-learn>=0.18->py_entitymatching) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scikit-learn>=0.18->py_entitymatching) (1.16.3)\n",
      "Requirement already satisfied: jinja2>=2.8 in /usr/local/lib/python2.7/dist-packages (from pandas-profiling>=1.4.0->py_entitymatching) (2.10.1)\n",
      "Requirement already satisfied: matplotlib>=1.4 in /usr/local/lib/python2.7/dist-packages (from pandas-profiling>=1.4.0->py_entitymatching) (2.2.4)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas>=0.16.0->py_stringsimjoin==0.3.0->py_entitymatching) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas>=0.16.0->py_stringsimjoin==0.3.0->py_entitymatching) (2.5.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python2.7/dist-packages (from jinja2>=2.8->pandas-profiling>=1.4.0->py_entitymatching) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.4->pandas-profiling>=1.4.0->py_entitymatching) (0.10.0)\n",
      "Requirement already satisfied: backports.functools-lru-cache in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.4->pandas-profiling>=1.4.0->py_entitymatching) (1.5)\n",
      "Requirement already satisfied: subprocess32 in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.4->pandas-profiling>=1.4.0->py_entitymatching) (3.5.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.4->pandas-profiling>=1.4.0->py_entitymatching) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4->pandas-profiling>=1.4.0->py_entitymatching) (41.0.1)\n",
      "Building wheels for collected packages: py-entitymatching, PyPrind, py-stringsimjoin, py-stringmatching\n",
      "  Building wheel for py-entitymatching (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/11/32/31986854281ff89654b9e67c1cb5d94dd8f87d7408aaef3c91\n",
      "  Building wheel for PyPrind (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/ed/f4/966a298352e737031124486720b3ec37d7ab4ae57328ee1021\n",
      "  Building wheel for py-stringsimjoin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/a2/f7/b748da307ea9120633a58847b0ecec23c97cfccdf81d875282\n",
      "  Building wheel for py-stringmatching (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/60/7a/90/37ae79d15afb482c2fa1a58a45fadd1945ed1d09fc8d50d4b6\n",
      "Successfully built py-entitymatching PyPrind py-stringsimjoin py-stringmatching\n",
      "Installing collected packages: PyPrind, py-stringmatching, py-stringsimjoin, py-entitymatching\n",
      "Successfully installed PyPrind-2.11.2 py-entitymatching-0.3.1 py-stringmatching-0.4.1 py-stringsimjoin-0.3.0\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python2.7/dist-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy) (1.16.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (1.16.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.16.3)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.5.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install py_entitymatching\n",
    "!pip install scipy\n",
    "!pip install numpy\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9zlZOfbeJGm",
    "colab_type": "text"
   },
   "source": [
    "# Prep 2: enter the file location on your harddisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "tUrly8hweJGm",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "table_a = 'Table A.xls'\n",
    "table_b = 'Table B.xls'\n",
    "candidate_set = 'reducedTuplepairs.csv'\n",
    "prediction_set = 'Prediction list.xls'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5Kc-o9jeJGo",
    "colab_type": "text"
   },
   "source": [
    "# Prep 3: reading the files into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "6cgshl6XeJGo",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfa = pd.read_csv(table_a)\n",
    "dfb = pd.read_csv(table_b)\n",
    "dfc = pd.read_csv(candidate_set)\n",
    "dfp = pd.read_csv(prediction_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hub4sHpRZ82g"
   },
   "source": [
    "# Module: debug_blocker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "zsXcj_WqZ82d",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Example input format:\n",
    "# Format of table_a:\n",
    "# _id, attribute1, attribute2, ....., attributen\n",
    "\n",
    "# Format of table_b:\n",
    "# _id, attribute1, attribute2, ....., attributen\n",
    "\n",
    "# Format of candidate_set\n",
    "# A_id,B_id\n",
    "# where A_id is _id from table_a and B_id is the _id column value from table_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "s3YAFomhZ82a",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import py_entitymatching as em\n",
    "import pandas as pd\n",
    "\n",
    "def run_debug_blocker(table_a, table_b, table_a_key, table_b_key, candidate_set):\n",
    "    dfl = em.read_csv_metadata(table_a, key=table_a_key)\n",
    "    dfr = em.read_csv_metadata(table_b, key=table_b_key)\n",
    "\n",
    "    # reading the candidate set and adding key\n",
    "    dfcand = pd.read_csv(candidate_set)\n",
    "    dfcand.drop_duplicates(inplace=True)\n",
    "    dfcand.to_csv('cand_set_with_index.csv', index_label='id')\n",
    "\n",
    "    dfcset = em.read_csv_metadata('cand_set_with_index.csv', key='id', ltable=dfl, \n",
    "                                  rtable=dfr, fk_ltable='A_id', fk_rtable='B_id')\n",
    "\n",
    "    # running debug blocker to identify the records in A x B \\ C\n",
    "    debug_file = em.debug_blocker(dfcset, dfl, dfr)\n",
    "    \n",
    "    return debug_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "kdN6gQxOZ82X",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "debug_file = run_debug_blocker(table_a, table_b, '_id', '_id', candidate_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "1KNXkPh2Z82P",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "debug_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Y5NNXGXeJHD",
    "colab_type": "text"
   },
   "source": [
    "# Module: estimate_precision_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "4BuAYFoPeJHE",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from numpy import sqrt\n",
    "\n",
    "delta = .05\n",
    "Z = norm.ppf(1 - (delta / 2))\n",
    "\n",
    "def estimate_PR(labeled_pairs, reduced_cands, predicted_matches):\n",
    "    '''\n",
    "    labeled_pairs - a pandas dataframe with schema id1,id2,label\n",
    "                    Note label needs to be Boolean\n",
    "\n",
    "    reduced_cands - a pandas dataframe with schema id1,id2\n",
    "    predicted_matches - a pandas dataframe with schema id1,id2\n",
    "    \n",
    "    return:\n",
    "        ( (recall lower bound, recall upper bound), (precision lower bound, precision upper bound) )\n",
    "    '''\n",
    "\n",
    "    labeled_pairs.drop_duplicates(inplace=True)\n",
    "    labeled_pairs.columns = ['id1', 'id2', 'label']\n",
    "    reduced_cands.columns = ['id1', 'id2']\n",
    "    reduced_cand_set = set(zip(reduced_cands.id1, reduced_cands.id2))\n",
    "    predicted_matches = set(zip(predicted_matches.id1, predicted_matches.id2))\n",
    "    \n",
    "    # estimate the recall\n",
    "    # number of positives in the labeled sample\n",
    "    actual_pos = float(labeled_pairs.label.sum())\n",
    "    # the maximum number of postives in the candidate set\n",
    "    max_actual_pos = float(actual_pos + len(reduced_cand_set) - len(labeled_pairs))\n",
    "    \n",
    "    # true positives in the labeled sample\n",
    "    true_pos = float(labeled_pairs.apply(lambda x : (x['id1'], x['id2']) in predicted_matches and x['label'], axis=1).sum())\n",
    "    #estimated recall\n",
    "    recall = float(true_pos / actual_pos)\n",
    "\n",
    "    recall_error = Z * sqrt( ((recall * (1 - recall)) / (actual_pos)) * ((max_actual_pos - actual_pos) / (max_actual_pos - 1)) )\n",
    "\n",
    "\n",
    "    # estimate Precision\n",
    "    labeled_set  = set(zip(labeled_pairs.id1, labeled_pairs.id2))\n",
    "    predicted_pos = float(len(labeled_set & predicted_matches))\n",
    "    \n",
    "    predicted_pos_in_reduced_cand_set = float(len(reduced_cand_set & predicted_matches))\n",
    "    \n",
    "    alpha =  predicted_pos_in_reduced_cand_set / len(predicted_matches)\n",
    "    precision = alpha * (true_pos / predicted_pos)\n",
    "    \n",
    "    precision_error = alpha * Z * sqrt( ((precision * (1 - precision)) / predicted_pos) * (float((len(predicted_matches) - predicted_pos)) / (len(predicted_matches)  - 1)) )\n",
    "\n",
    "    return ((recall - recall_error, recall + recall_error),\n",
    "            (precision - precision_error, precision + precision_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6Vms7TCeJHF",
    "colab_type": "text"
   },
   "source": [
    "# Estimating Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lz446dgyeJHF",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "b4a61026-ba55-4216-efb8-2147ff79ebbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0.970093033882644, 0.9846239472494315), (0.9337969948257316, 0.9539917840521561))\n"
     ]
    }
   ],
   "source": [
    "# read the labeled pairs file, i.e. the file with the labels\n",
    "labeled_pairs = pd.read_csv('labelPairs_400.csv')\n",
    "print(estimate_PR(labeled_pairs, dfc, dfp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "mLZP7VO5eJHH",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "estimating_precision_recall.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "toc_visible": true
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
